+ queue=dcsc
+ [[ true = true ]]
+ ./mrun -a example_we -c .mrun.config -d example_we -h lchpc06 -H lchpc06 -m 64000 -t 3600000 -q dcsc -R 192.168.0.7 -U sboersma3 -u sboersma3 -G 'Rev: 2227M' -s 'palm.f90  wind_turbine_model_mod.f90' -i ' d3f prf maf' -K parallel -o ' d3f prf maf' -X 16 -T 8 -n not_shared -z

*** MRUN  2.1 Rev: 2186 $ 
    will be executed.     Please wait ......
#------------------------------------------------------------------------# 
| MRUN  2.1 Rev: 2186 $                    Fri Aug  4 18:10:09 CEST 2017 | 
|                                                                        | 
| called on:               n06-24                                        | 
| execution on:            lchpc06 (n06-24)                              | 
| number of PEs:           16                                            | 
| tasks per node:          8 (number of nodes: 2)                        | 
|                                                                        | 
| make options:            -j 16                                         | 
| cpp directives:          -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION | 
|                           -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf | 
|                           -D__lc -D__parallel                          | 
| compiler options:        -Ofast -ffree-line-length-none -I /home/sboer | 
|                          sma3/palm/binaries/include -I /usr/include    | 
| linker options:          -Ofast -ffree-line-length-none /home/sboersma | 
|                          3/palm/binaries/lib/libnetcdff.so /usr/lib64/ | 
|                          libfftw3.so                                   | 
| modules to be load:                                                    | 
| main program:            palm.f90                                      | 
|                                                                        | 
| base name of files:      example_we                                    | 
| INPUT control list:      d3f prf maf                                   | 
| OUTPUT control list:     d3f prf maf                                   | 
|                                                                        | 
| Files to be compiled:                                                  | 
| palm.f90 wind_turbine_model_mod.f90                                    | 
#------------------------------------------------------------------------#
  *** changed to temporary directory: /home/sboersma3/palm/current_version/tmp/sboersma3.10836


  *** compilation starts 
  ----------------------------------------------------------------------------
  *** compilation with make using following options:
      make depository:          /home/sboersma3/palm/current_version/MAKE_DEPOSITORY_parallel/palm_current_version.tar      make options:             -j 16
      compilername:             /home/sboersma3/palm/binaries/bin/mpif90
      compiler options:         -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include 
      preprocessor directives:  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel 
      linker options:           -Ofast -ffree-line-length-none /home/sboersma3/palm/binaries/lib/libnetcdff.so /usr/lib64/libfftw3.so  
      source code files:        palm.f90  wind_turbine_model_mod.f90 
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c wind_turbine_model_mod.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c palm.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c check_parameters.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c init_3d_model.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c parin.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c prognostic_equations.f90
/home/sboersma3/palm/binaries/bin/mpif90 -Ofast -ffree-line-length-none -I /home/sboersma3/palm/binaries/include -I /usr/include  -cpp -D__fftw -DMPI_REAL=MPI_DOUBLE_PRECISION -DMPI_2REAL=MPI_2DOUBLE_PRECISION -D__netcdf -D__lc -D__parallel -c time_integration.f90
/home/sboersma3/palm/binaries/bin/mpif90 -o a.out advec_s_bc.o advec_s_pw.o advec_s_up.o advec_ws.o advec_u_pw.o advec_u_up.o advec_v_pw.o advec_v_up.o advec_w_pw.o advec_w_up.o average_3d_data.o boundary_conds.o buoyancy.o calc_liquid_water_content.o calc_mean_profile.o calc_radiation.o check_for_restart.o check_open.o check_parameters.o close_file.o compute_vpt.o coriolis.o cpulog_mod.o data_log.o data_output_dvrp.o data_output_mask.o data_output_profiles.o data_output_ptseries.o data_output_spectra.o data_output_flight.o data_output_tseries.o data_output_2d.o data_output_3d.o diffusion_e.o diffusion_s.o diffusion_u.o diffusion_v.o diffusion_w.o diffusivities.o disturb_field.o disturb_heatflux.o eqn_state_seawater.o exchange_horiz.o exchange_horiz_2d.o fft_xy_mod.o flow_statistics.o global_min_max.o header.o inflow_turbulence.o init_1d_model.o init_3d_model.o init_advec.o init_cloud_physics.o init_coupling.o init_dvrp.o init_grid.o init_masks.o init_ocean.o init_pegrid.o init_pt_anomaly.o init_rankine.o init_slope.o interaction_droplets_ptq.o land_surface_model_mod.o local_stop.o local_system.o local_tremain.o local_tremain_ini.o lpm.o lpm_advec.o lpm_boundary_conds.o lpm_calc_liquid_water_content.o lpm_collision_kernels.o lpm_data_output_particles.o lpm_droplet_collision.o lpm_droplet_condensation.o lpm_exchange_horiz.o lpm_init.o lpm_init_sgs_tke.o lpm_pack_arrays.o lpm_read_restart_file.o lpm_set_attributes.o lpm_write_exchange_statistics.o lpm_write_restart_file.o ls_forcing_mod.o message.o microphysics_mod.o modules.o mod_kinds.o mod_particle_attributes.o netcdf_interface_mod.o nudging_mod.o outflow_turbulence.o package_parin.o palm.o parin.o plant_canopy_model_mod.o pmc_interface_mod.o pmc_child_mod.o pmc_general_mod.o pmc_handle_communicator_mod.o pmc_mpi_wrapper_mod.o pmc_parent_mod.o poisfft_mod.o poismg_mod.o poismg_noopt.o posix_calls_from_fortran.o pres.o print_1d.o production_e.o prognostic_equations.o progress_bar_mod.o radiation_model_mod.o random_function_mod.o random_gauss.o random_generator_parallel_mod.o read_3d_binary.o read_var_list.o run_control.o set_slicer_attributes_dvrp.o singleton_mod.o sor.o spectra_mod.o subsidence_mod.o sum_up_3d_data.o surface_coupler.o surface_layer_fluxes_mod.o swap_timelevel.o temperton_fft_mod.o time_integration.o time_to_string.o timestep.o timestep_scheme_steering.o transpose.o tridia_solver_mod.o urban_surface_mod.o user_3d_data_averaging.o user_actions.o user_additional_routines.o user_check_data_output.o user_check_data_output_pr.o user_check_parameters.o user_data_output_2d.o user_data_output_3d.o user_data_output_dvrp.o user_data_output_mask.o user_define_netcdf_grid.o user_dvrp_coltab.o user_header.o user_init.o user_init_3d_model.o user_init_flight.o user_init_grid.o user_init_land_surface.o user_init_plant_canopy.o user_init_radiation.o user_flight.o user_init_urban_surface.o user_last_actions.o user_lpm_advec.o user_lpm_init.o user_lpm_set_attributes.o user_module.o user_parin.o user_read_restart_data.o user_spectra.o user_statistics.o virtual_flight_mod.o wall_fluxes.o wind_turbine_model_mod.o write_3d_binary.o write_var_list.o -Ofast -ffree-line-length-none /home/sboersma3/palm/binaries/lib/libnetcdff.so /usr/lib64/libfftw3.so 
  ----------------------------------------------------------------------------
  *** compilation finished 


  *** providing INPUT-files:
  ----------------------------------------------------------------------------
  >>> INPUT: /home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_p3df  to  PARIN
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_rlw.nc" 
                   is not available!
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_rsw.nc" 
                   is not available!
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_rsnd.nc" 
                   is not available!
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_topo" 
                   is not available!
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_nudge" 
                   is not available!
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_lsf" 
                   is not available!
  >>> INPUT: /home/sboersma3/palm/current_version/JOBS/example_we/RESTART/example_we_d3d/....  to  BININ
      directory will be fetched from temporary directory "/home/sboersma3/palm/current_version/RESTART_DATA" !
  *** INFORMATIVE: input file "/home/sboersma3/palm/current_version/JOBS/example_we/OUTPUT/example_we_pr.nc" 
                   is not available!
  >>> INPUT: /home/sboersma3/palm/current_version/JOBS/example_we/INPUT/example_we_wtm  to  WTM_DATA
  ----------------------------------------------------------------------------
  *** all INPUT-files provided 


  *** execution starts in directory
      "/home/sboersma3/palm/current_version/tmp/sboersma3.10836"
  ----------------------------------------------------------------------------


      ... reading environment parameters from ENVPAR      --- finished
      ... reading NAMELIST parameters from PARIN      --- finished
      ... creating virtual PE grids + MPI derived data types      --- finished
      ... checking parameters      --- finished
      ... allocating arrays      --- finished
      ... initializing in case of restart / cyclic_fill      --- finished
      ... initializing wind turbine model      --- finished
      --- leaving init_3d_model
      --- start with time-stepping
At line 158 of file progress_bar_mod.f90 (unit = 117, file = 'PROGRESS')
Fortran runtime error: Stale file handle

Error termination. Backtrace:

Could not print backtrace: /proc/self/exe: Stale file handle
#0  0x2adbcfcacefa
#1  0x2adbcfcad9d5
#2  0x2adbcfcae129
#3  0x2adbcfd758b2
#4  0x2adbcfd64125
#5  0x663e40
#6  0x6e7c54
#7  0x5e64f0
#8  0x403c6c
#9  0x2adbd0e3db34
#10  0x403cbb
#11  0xffffffffffffffff
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).............: MPI_Allreduce(sbuf=0x114d740, rbuf=0x114c950, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000004) failed
MPIR_Allreduce_impl(764).......: 
MPIR_Allreduce_intra(257)......: 
allreduce_intra_or_coll_fn(163): 
MPIR_Allreduce_intra(502)......: 
MPIC_Sendrecv(483).............: 
MPIDI_EagerContigIsend(573)....: failure occurred while attempting to send an eager message
MPIDI_CH3_iSendv(34)...........: Communication error with rank 0
MPIR_Allreduce_intra(567)......: 
MPIC_Sendrecv(483).............: 
MPIDI_EagerContigIsend(573)....: failure occurred while attempting to send an eager message
MPIDI_CH3_iSendv(34)...........: Communication error with rank 0
MPIR_Allreduce_intra(268)......: 
MPIR_Bcast_impl(1452)..........: 
MPIR_Bcast(1476)...............: 
MPIR_Bcast_intra(1287).........: 
MPIR_Bcast_binomial(310).......: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x2ca81f0, rbuf=0x2ca7400, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x12941f0, rbuf=0x1293400, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x109bcd0, rbuf=0x109aee0, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x1f28cc0, rbuf=0x1f27ed0, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x2b90cb0, rbuf=0x2b8fec0, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0x18b4cb0, rbuf=0x18b3ec0, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
Fatal error in MPI_Allreduce: Unknown error class, error stack:
MPI_Allreduce(907).......: MPI_Allreduce(sbuf=0xeb6cb0, rbuf=0xeb5ec0, count=444, MPI_DOUBLE_PRECISION, MPI_SUM, comm=0x84000002) failed
MPIR_Allreduce_impl(764).: 
MPIR_Allreduce_intra(268): 
MPIR_Bcast_impl(1452)....: 
MPIR_Bcast(1476).........: 
MPIR_Bcast_intra(1287)...: 
MPIR_Bcast_binomial(310).: Failure during collective
[mpiexec@n06-24] HYDT_bscd_pbs_wait_for_completion (/home/sboersma3/palm/mpich-3.2/src/pm/hydra/tools/bootstrap/external/pbs_wait.c:67): tm_poll(obit_event) failed with TM error 17002
[mpiexec@n06-24] HYDT_bsci_wait_for_completion (/home/sboersma3/palm/mpich-3.2/src/pm/hydra/tools/bootstrap/src/bsci_wait.c:23): launcher returned error waiting for completion

  +++ runtime error occured[proxy:0:1@n06-23] HYD_pmcd_pmip_control_cmd_cb (/home/sboersma3/palm/mpich-3.2/src/pm/hydra/pm/pmiserv/pmip_cb.c:885): assert (!closed) failed
[proxy:0:1@n06-23] HYDT_dmxu_poll_wait_for_event (/home/sboersma3/palm/mpich-3.2/src/pm/hydra/tools/demux/demux_poll.c:76): callback returned error status
[proxy:0:1@n06-23] main (/home/sboersma3/palm/mpich-3.2/src/pm/hydra/pm/pmiserv/pmip.c:206): demux engine error waiting for event

  *** Execution of ERROR-command:
  >>> [[ $locat = execution ]]  &&  cat  RUN_CONTROL
cat: RUN_CONTROL: No such file or directory


+++ MRUN killed 

+ ls -al
total 192
drwxr-x---  3 sboersma3 domain users     85 Aug  5 00:27 .
drwxr-x--- 10 sboersma3 domain users   4096 Aug  5 00:27 ..
-rwxr-----  1 sboersma3 domain users 174160 Aug  4 18:10 mrun
-rw-r-----  1 sboersma3 domain users  14939 Aug  4 18:10 .mrun.config
drwxr-x---  2 sboersma3 domain users     85 Aug  4 18:10 SOURCES_FOR_RUN_example_we
++ pwd
+ echo /home/sboersma3/palm/current_version/tmp/sboersma3.31316
/home/sboersma3/palm/current_version/tmp/sboersma3.31316
+ cd /home/sboersma3
